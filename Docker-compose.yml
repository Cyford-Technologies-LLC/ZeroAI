services:
  redis:
    image: redis:7-alpine
    container_name: zeroai_redis
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  zeroai:
    build: .
    container_name: zeroai_api-prod
    ports:
      - "0.0.0.0:3939:3939"
      - "0.0.0.0:333:333"
    volumes:
      - .:/app
#      - zeroai_venv:/app/venv
      - /etc/cyford/zeroai/knowledge:/app/knowledge
      - /etc/cyford/zeroai/data:/app/data
      - /etc/cyford/zeroai/backup:/app/backup
      - /etc/cyford/zeroai/.env:/app/.env:ro
#      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://ollama:11434
      - PHP_OPCACHE_ENABLE=1
      - PHP_OPCACHE_MEMORY=256
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    env_file:
      - .env
    depends_on:
      - ollama
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 1.5G


  peer:
    build: .
    container_name: zeroai_peer-prod
    ports:
      - "0.0.0.0:8080:8080"
    volumes:
      - .:/app
#      - zeroai_venv:/app/venv
      - /etc/cyford/zeroai/knowledge:/app/knowledge
      - /etc/cyford/zeroai/data:/app/data
      - /etc/cyford/zeroai/backup:/app/backup
      - /etc/cyford/zeroai/.env:/app/.env:ro
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://ollama:11434
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    env_file:
      - .env
    command: >
      bash -c "mkdir -p /app/data && chown -R www-data:www-data /app/data && chmod -R 775 /app/data && 
      python3 /app/scripts/cron_runner.py & 
      /app/venv/bin/gunicorn API.persistent_crew_api:app --bind 0.0.0.0:8080 --worker-class uvicorn.workers.UvicornWorker --workers 2 --preload --timeout 300"
    depends_on:
      - ollama
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  ollama:
    image: ollama/ollama:latest
    container_name: zeroai_ollama
    ports:
      - "0.0.0.0:11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

volumes:
  ollama_data:
  redis_data: