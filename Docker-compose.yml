services:
  zeroai:
      build: .
      container_name: zeroai_api-prod
#      privileged: true
      ports:
        - "3939:3939"
        - "333:333"
      volumes:
        - ./src:/app/src
        - ./API:/app/API
        - ./run:/app/run
        - ./config:/app/config
        - ./examples:/app/examples
        - ./knowledge:/app/knowledge
        - ./logs:/app/logs
        - /etc/cyford/zeroai/.env:/etc/cyford/zeroai/.env:ro
        - /var/run/docker.sock:/var/run/docker.sock
      environment:
        - PYTHONPATH=/app
        - OLLAMA_HOST=http://ollama:11434
        - LOCAL_UID=${LOCAL_UID}
        - LOCAL_GID=${LOCAL_GID}
      env_file:
        - .env
        - /etc/cyford/zeroai/.env
      user: "root"  # Add or ensure this line is present
      depends_on:
        - ollama
      restart: unless-stopped

  peer:
    build: .
    container_name: zeroai_peer-prod
    ports:
      - "8080:8080"
    volumes:
      - ./src:/app/src
      - ./API:/app/API
      - ./run:/app/run
      - ./config:/app/config
      - ./examples:/app/examples
      - ./knowledge:/app/knowledge
      - ./logs:/app/logs
      - /etc/cyford/zeroai/.env:/etc/cyford/zeroai/.env:ro
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://ollama:11434
      - LOCAL_UID=${LOCAL_UID}
      - LOCAL_GID=${LOCAL_GID}
    env_file:
      - .env
      - /etc/cyford/zeroai/.env
    command: ["/app/venv/bin/gunicorn", "API.persistent_crew_api:app", "--bind", "0.0.0.0:8080", "--worker-class", "uvicorn.workers.UvicornWorker", "--workers", "2", "--preload"]
    depends_on:
      - ollama
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: zeroai_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

volumes:
  ollama_data: