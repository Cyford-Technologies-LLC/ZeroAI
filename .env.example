# ZeroAI Environment Variables
# Zero Cost. Zero Cloud. Zero Limits.
# Copy this file to .env and fill in your API keys

# ===== LOCAL AI SETTINGS =====
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama3.1:8b

# ===== GPU CLOUD PROVIDERS =====
GPU_ACCESS_ENABLED=true
GPU_PROVIDER_PRIORITY=manual,thunder  # Manual GPU first, then Thunder

# Thunder Compute
THUNDER_ENABLED=true
THUNDER_AUTO_START=true
THUNDER_COMPLEXITY_THRESHOLD=7
THUNDER_API_KEY=your_thunder_api_key_here
THUNDER_INSTANCE_ID=your_instance_id_here

# Manual GPU Instance (Prime Intellect, RunPod, etc.)
MANUAL_GPU_ENABLED=true
MANUAL_GPU_NAME=Prime Intellect RTX 3070
MANUAL_GPU_ENDPOINT=  # Set this to your instance's Ollama endpoint

# Prime Intellect (for reference - no API needed)
# Instance: refreshing-mottled-pillbug
# Dashboard: https://app.primeintellect.ai/dashboard/instances
# Cost: $0.16/hr

# ===== CLOUD AI PROVIDERS =====
# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude (https://console.anthropic.com/)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Azure OpenAI (https://portal.azure.com/)
AZURE_OPENAI_API_KEY=your_azure_openai_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Google AI (https://makersuite.google.com/app/apikey)
GOOGLE_API_KEY=your_google_api_key_here

# ===== APPLICATION SETTINGS =====
LOG_LEVEL=INFO
MAX_CONCURRENT_AGENTS=3
AGENT_TIMEOUT=300
LOCAL_ONLY_MODE=false