version: '3.8'

services:
#  redis:
#    image: redis:7-alpine
#    container_name: zeroai_redis-test
#    ports:
#      - "127.0.0.1:6380:6379"
#    volumes:
#      - redis_data_test:/data
#    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
#    restart: unless-stopped
#    deploy:
#      resources:
#        limits:
#          memory: 512M
#        reservations:
#          memory: 256M

  zeroai-test:
    build: .
    container_name: zeroai_api-test
    ports:
      - "0.0.0.0:3940:3939"
      - "0.0.0.0:334:333"
    volumes:
      - .:/app
      - /etc/cyford/zeroai/knowledge:/app/knowledge
      - /etc/cyford/zeroai/data:/app/data
      - /etc/cyford/zeroai/backup:/app/backup
      - /etc/cyford/zeroai/.env:/app/.env:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://ollama:11434
      - PHP_OPCACHE_ENABLE=1
      - PHP_OPCACHE_MEMORY=256
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    env_file:
      - .env
#    depends_on:
#      - ollama
#      - redis
#      - avatar
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 1.5G

#  peer:
#    build: .
#    container_name: zeroai_peer-test
#    ports:
#      - "0.0.0.0:8081:8080"
#    volumes:
#      - .:/app
#      - /etc/cyford/zeroai/knowledge:/app/knowledge
#      - /etc/cyford/zeroai/data:/app/data
#      - /etc/cyford/zeroai/backup:/app/backup
#      - /etc/cyford/zeroai/.env:/app/.env:ro
#    environment:
#      - PYTHONPATH=/app
#      - OLLAMA_HOST=http://ollama:11434
#      - REDIS_HOST=redis
#      - REDIS_PORT=6379
#    env_file:
#      - .env
#    command: >
#      bash -c "mkdir -p /app/data && chown -R www-data:www-data /app/data && chmod -R 775 /app/data &&
#      python3 /app/scripts/cron_runner.py &
#      /app/venv/bin/gunicorn API.persistent_crew_api:app --bind 0.0.0.0:8080 --worker-class uvicorn.workers.UvicornWorker --workers 2 --preload --timeout 300"
#    depends_on:
#      - ollama
#      - redis
#    restart: unless-stopped
#    deploy:
#      resources:
#        limits:
#          memory: 2G
#        reservations:
#          memory: 1G
#
#  ollama:
#    image: ollama/ollama:latest
#    container_name: zeroai_ollama-test
#    ports:
#      - "0.0.0.0:11435:11434"
#    volumes:
#      - ollama_data_test:/root/.ollama
#    restart: unless-stopped
#    deploy:
#      resources:
#        limits:
#          memory: 8G
#        reservations:
#          memory: 4G
#
#  tts-service:
#    build: ./tts
#    container_name: zeroai_tts-service-test
#    ports:
#      - "0.0.0.0:5001:5000"  # Different port to avoid conflict
#    restart: unless-stopped
#    deploy:
#      resources:
#        limits:
#          memory: 1G
#        reservations:
#          memory: 512M
#
#  avatar:
#    build: ./avatar
#    container_name: zeroai_avatar-test
#    ports:
#      - "7861:7860"
#    volumes:
#      - ./avatars:/app/avatars
#      - avatar_models_test:/app/checkpoints
#    environment:
#      - OLLAMA_HOST=http://ollama:11434
#      - TTS_API_URL=http://tts-service:5000/synthesize  # ADDED TTS CONNECTION
#    depends_on:
#      - ollama
#      - tts-service  # ADDED TTS DEPENDENCY
#    restart: unless-stopped
#    deploy:
#      resources:
#        limits:
#          memory: 6G
#        reservations:
#          memory: 3G

#volumes:
#  ollama_data_test:
#  redis_data_test:
#  avatar_models_test: